# Semantic Kernel LLM Configuration

# Default model to use
default_model: "gpt-4"

# LLM Models Configuration
models:
  # OpenAI Models
  gpt-4:
    provider: "openai"
    model_id: "gpt-4"
    api_key_env: "OPENAI_API_KEY"
    endpoint: null  # uses default OpenAI endpoint
    max_tokens: 4096
    temperature: 0.7

  gpt-4-turbo:
    provider: "openai"
    model_id: "gpt-4-turbo-preview"
    api_key_env: "OPENAI_API_KEY"
    endpoint: null
    max_tokens: 4096
    temperature: 0.7

  gpt-3.5-turbo:
    provider: "openai"
    model_id: "gpt-3.5-turbo"
    api_key_env: "OPENAI_API_KEY"
    endpoint: null
    max_tokens: 4096
    temperature: 0.7

  # Azure OpenAI Models
  azure-gpt-4:
    provider: "azure_openai"
    model_id: "gpt-4"
    deployment_name: "gpt-4-deployment"  # Your Azure deployment name
    api_key_env: "AZURE_OPENAI_API_KEY"
    endpoint_env: "AZURE_OPENAI_ENDPOINT"
    api_version: "2024-02-15-preview"
    max_tokens: 4096
    temperature: 0.7

  # Anthropic Claude Models
  claude-3-opus:
    provider: "anthropic"
    model_id: "claude-3-opus-20240229"
    api_key_env: "ANTHROPIC_API_KEY"
    endpoint: null
    max_tokens: 4096
    temperature: 0.7

  claude-3-sonnet:
    provider: "anthropic"
    model_id: "claude-3-sonnet-20240229"
    api_key_env: "ANTHROPIC_API_KEY"
    endpoint: null
    max_tokens: 4096
    temperature: 0.7

# Routing Configuration
routing:
  # Rules for prompt routing based on keywords or patterns
  rules:
    - name: "code_generation"
      keywords: ["code", "implement", "function", "class", "programming"]
      preferred_model: "gpt-4"

    - name: "analysis"
      keywords: ["analyze", "explain", "understand", "review"]
      preferred_model: "claude-3-sonnet"

    - name: "creative"
      keywords: ["write", "story", "creative", "imagine"]
      preferred_model: "gpt-4-turbo"

    - name: "quick_tasks"
      keywords: ["quick", "simple", "summarize"]
      preferred_model: "gpt-3.5-turbo"

  # Default fallback model when no rules match
  fallback_model: "gpt-3.5-turbo"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/semantic-k.log"
