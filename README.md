# Semantic-K Weather Chat

Aplikacja webowa z interfejsem czatu do interakcji z asystentem pogodowym, wykorzystujÄ…ca GPT-5 z inteligentnym routingiem opartym na konfiguracji YAML.

## âœ¨ Funkcje

- **ğŸŒ¤ï¸ Inteligentny Routing**: Automatyczna klasyfikacja promptÃ³w jako WEATHER lub OTHER
- **âš™ï¸ Konfiguracja YAML**: Wszystkie ustawienia w jednym pliku `config.yml`
- **ğŸ“Š Meta Dane**: WyÅ›wietlanie szczegÃ³Å‚owych informacji o klasyfikacji
- **ğŸ’¬ Streaming Odpowiedzi**: Przyrostowe wyÅ›wietlanie odpowiedzi modelu
- **ğŸ¨ Bootstrap 5 UI**: Nowoczesny, responsywny interfejs uÅ¼ytkownika
- **ğŸ’¾ Sesje Czatu**: Historia rozmowy utrzymywana podczas sesji

## ğŸš€ Szybki Start

### 1. Instalacja

```bash
# Sklonuj repozytorium
git clone <repository-url>
cd semantic-k

# Zainstaluj zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

### 2. Konfiguracja

```bash
# UtwÃ³rz plik .env z kluczem API
cp .env.example .env
# Edytuj .env i dodaj: OPENAI_API_KEY=sk-proj-your-key-here
```

### 3. Uruchomienie

```bash
# Linux/Mac
./start.sh

# Windows
start.bat

# Lub rÄ™cznie
python simple_server.py
```

### 4. UÅ¼ycie

OtwÃ³rz przeglÄ…darkÄ™: [http://localhost:8000](http://localhost:8000)

## ğŸ“‹ Konfiguracja (config.yml)

CaÅ‚a aplikacja jest konfigurowana przez plik `config.yml`:

```yaml
# DomyÅ›lny model
default_model: "gpt-5"

# DostÄ™pne modele
models:
  gpt-5:
    provider: "openai"
    model_id: "gpt-5"
    api_key_env: "OPENAI_API_KEY"
    max_tokens: 50000
    temperature: 0.7

# ReguÅ‚y routingu
routing:
  rules:
    - name: "WEATHER"
      keywords: ["weather", "pogoda", "temperatura", ...]
      preferred_model: "gpt-5"
      system_prompt: "You are a weather information assistant..."
    
    - name: "OTHER"
      keywords: []
      preferred_model: "gpt-5"
      system_prompt: "Przepraszam, ale nie posiadam informacji..."
  
  fallback_model: "gpt-5"
```

### Dostosowanie

#### Dodawanie sÅ‚Ã³w kluczowych
```yaml
keywords: ["weather", "pogoda", "twoje_nowe_slowo"]
```

#### Zmiana promptÃ³w systemowych
```yaml
system_prompt: "TwÃ³j wÅ‚asny system prompt"
```

#### Zmiana parametrÃ³w modelu
```yaml
temperature: 0.8  # 0.0 - 1.0
max_tokens: 100000
```

## ğŸ—ï¸ Architektura

```
semantic-k/
â”œâ”€â”€ simple_server.py       # âš™ï¸ FastAPI server (czyta config.yml)
â”œâ”€â”€ config.yml             # ğŸ¯ CAÅA KONFIGURACJA
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html         # ğŸ¨ Bootstrap 5 UI
â”œâ”€â”€ .env                   # ğŸ”‘ Klucze API
â””â”€â”€ requirements.txt       # ğŸ“¦ ZaleÅ¼noÅ›ci Python
```

### PrzepÅ‚yw danych

1. **UÅ¼ytkownik** â†’ WysyÅ‚a prompt przez UI
2. **simple_server.py** â†’ Åaduje `config.yml` przy starcie
3. **Klasyfikacja** â†’ UÅ¼ywa `keywords` z config do klasyfikacji
4. **Routing** â†’ Wybiera `preferred_model` z config
5. **Generowanie** â†’ UÅ¼ywa `system_prompt` i parametrÃ³w z config
6. **Streaming** â†’ Zwraca odpowiedÅº do UI

## ğŸ”Œ API Endpoints

| Endpoint | Metoda | Opis |
|----------|--------|------|
| `/` | GET | Zwraca frontend HTML |
| `/api/chat` | POST | Chat ze streamingiem (SSE) |
| `/api/reset` | POST | Reset sesji czatu |
| `/health` | GET | Health check + info o config |
| `/api/config` | GET | Aktualna konfiguracja (bez kluczy) |

### PrzykÅ‚ad uÅ¼ycia API

```bash
# WysÅ‚anie wiadomoÅ›ci
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Jaka jest pogoda?"}'

# Sprawdzenie konfiguracji
curl http://localhost:8000/api/config

# Health check
curl http://localhost:8000/health
```

## ğŸ“Š Meta Dane

KaÅ¼dy prompt generuje nastÄ™pujÄ…ce meta dane:

```json
{
  "topic": "WEATHER",
  "topic_relevance": 0.75,
  "is_dangerous": 0.0,
  "is_continuation": 0.8,
  "topic_change": 0.1,
  "summary": "Prompt classified as WEATHER with 2 matching keyword(s)."
}
```

## ğŸ› ï¸ RozwÃ³j

### Uruchomienie w trybie deweloperskim

```bash
# Z hot-reload
uvicorn simple_server:app --reload --host 0.0.0.0 --port 8000
```

### Testowanie

```bash
# Zainstaluj dev dependencies
pip install -r requirements.txt

# Uruchom testy
pytest tests/
```

### Formatowanie kodu

```bash
black simple_server.py
ruff check simple_server.py
```

## ğŸ”§ Troubleshooting

### BÅ‚Ä…d: "OPENAI_API_KEY not set"
**RozwiÄ…zanie**: UtwÃ³rz plik `.env` z kluczem API

### BÅ‚Ä…d: "config.yml not found"
**RozwiÄ…zanie**: Upewnij siÄ™, Å¼e `config.yml` jest w gÅ‚Ã³wnym katalogu

### BÅ‚Ä…d: Port 8000 zajÄ™ty
**RozwiÄ…zanie**: ZmieÅ„ port w `simple_server.py` (ostatnia linia)

### BÅ‚Ä…d: Model nie dziaÅ‚a
**RozwiÄ…zanie**: SprawdÅº czy masz dostÄ™p do GPT-5 w swoim kluczu API

## ğŸ“ PrzykÅ‚adowe Prompty

### WEATHER (specjalny system prompt)
- "Jaka jest pogoda w Warszawie?"
- "Will it rain tomorrow?"
- "Temperatura w Krakowie?"

### OTHER (informacja o braku specjalizacji)
- "Co to jest Python?"
- "Napisz funkcjÄ™ sortujÄ…cÄ…"
- "Tell me a joke"

## ğŸŒŸ Zalety tego rozwiÄ…zania

âœ… **Centralna konfiguracja** - wszystko w `config.yml`  
âœ… **Åatwa modyfikacja** - zmieÅ„ keywords bez kodu  
âœ… **Bezpieczne** - klucze API w `.env`, nie w kodzie  
âœ… **Skalowalne** - Å‚atwo dodaÄ‡ nowe modele  
âœ… **Przejrzyste** - jasny przepÅ‚yw danych  

## ğŸ“– Dokumentacja

- [START_HERE.md](START_HERE.md) - Szybki start dla nowych uÅ¼ytkownikÃ³w
- [config.yml](config.yml) - Komentarze w pliku konfiguracji

## ğŸ¤ WkÅ‚ad

Pull requesty sÄ… mile widziane! Przed wysÅ‚aniem PR:

1. SprawdÅº formatowanie: `black .`
2. Uruchom linting: `ruff check .`
3. Przetestuj zmiany lokalnie

## ğŸ“§ Wsparcie

W razie problemÃ³w:
1. SprawdÅº [Troubleshooting](#-troubleshooting)
2. Przejrzyj logi serwera
3. SprawdÅº [START_HERE.md](START_HERE.md)

## ğŸ“œ Licencja

[Dodaj swojÄ… licencjÄ™]

---

**Stworzone z â¤ï¸ uÅ¼ywajÄ…c FastAPI, OpenAI GPT-5 i Bootstrap 5**